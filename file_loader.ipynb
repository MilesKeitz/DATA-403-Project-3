{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815f075b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432345db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f5722",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extration\n",
    "with zipfile.ZipFile(\"Alex.zip\") as z:\n",
    "    z.extractall(\"alex_data\")\n",
    "\n",
    "with zipfile.ZipFile(\"Kelly.zip\") as z:\n",
    "    z.extractall(\"kelly_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462481e2",
   "metadata": {},
   "source": [
    "After loading each folder, I created a new folder in the environment called \"data\" and put both the alex_data and kelly_data into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26190e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the images into tensors which is the data structure for PyTorch\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")), # ensures each images has RGB components\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(\"data\", transform = transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148f3f1",
   "metadata": {},
   "source": [
    "I resized each of the images to 224 x 224 but we can adjust this if needed. I read that each of the images should be the same size but I'm not too sure how much data we are using by downsizing the images.\n",
    "\n",
    "The batch size is the number of samples in one batch which we can change if we need. In the network, it will process 32 images at a time, update the weights, then move to the next 32 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94264383",
   "metadata": {},
   "source": [
    "# Inspect image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe875db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "tensor(0.0353) tensor(0.8431)\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape)        \n",
    "print(img_tensor.min(), img_tensor.max())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040174c",
   "metadata": {},
   "source": [
    "3 is the number of channels. In this case it is (R, G, B)\n",
    "\n",
    "224 x 224 is the height x width of the image\n",
    "\n",
    "Also shows the min amd max pixel values and they are normalized to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "R: 0.30980393290519714 G: 0.2666666805744171 B: 0.2862745225429535\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(loader))\n",
    "\n",
    "img = images[0]\n",
    "print(img.shape)\n",
    "\n",
    "r, g, b = img[:, 100, 150]\n",
    "print(\"R:\", r.item(), \"G:\", g.item(), \"B:\", b.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8d103",
   "metadata": {},
   "source": [
    "First line: 3 is the RGB channels, 224 x 224 is the size of the image\n",
    "\n",
    "Second line: The RGB values for a specific pixel in image 0. The values are between 0 and 1 because of ToTensor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
