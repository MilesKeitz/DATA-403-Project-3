{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a32738",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import torch, random, numpy as np, os\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76350c21",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519569ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(mod, train_loader, optimizer, device):\n",
    "    mod.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mod(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(mod, val_loader, device):\n",
    "    mod.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = mod(images)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return accuracy_score(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42952d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = seed\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804311e",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900e27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")), # ensures each images has RGB components\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder(\"data\", transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823fef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=0.4,\n",
    "                            drop_path_rate=0.1,\n",
    "                            num_classes=2)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "model.eval()\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc9f1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6907216494845361\n"
     ]
    }
   ],
   "source": [
    "for m in model.modules():\n",
    "    if m.__class__.__name__ == \"Dropout\":\n",
    "        m.p = 0.0\n",
    "    if m.__class__.__name__ == \"DropPath\":\n",
    "        m.drop_prob = 0.0\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_one_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "accuracy = evaluate(model, val_loader, device)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806f81a",
   "metadata": {},
   "source": [
    "# Drop Rate and Drop Path Rate Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee3ca6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rates(drop_rate, drop_path_rate, seed = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=drop_rate,\n",
    "                            drop_path_rate=drop_path_rate,\n",
    "                            num_classes=2)\n",
    "    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Dropout\":\n",
    "            m.p = 0.0\n",
    "        if m.__class__.__name__ == \"DropPath\":\n",
    "            m.drop_prob = 0.0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "    return acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965dac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR: 0.0 DPR: 0.0 Accuracy: 0.7216\n",
      "DR: 0.0 DPR: 0.1 Accuracy: 0.7216\n",
      "DR: 0.0 DPR: 0.2 Accuracy: 0.7216\n",
      "DR: 0.2 DPR: 0.0 Accuracy: 0.7113\n",
      "DR: 0.2 DPR: 0.1 Accuracy: 0.7113\n",
      "DR: 0.2 DPR: 0.2 Accuracy: 0.7113\n",
      "DR: 0.3 DPR: 0.0 Accuracy: 0.6907\n",
      "DR: 0.3 DPR: 0.1 Accuracy: 0.6907\n",
      "DR: 0.3 DPR: 0.2 Accuracy: 0.6907\n",
      "DR: 0.4 DPR: 0.0 Accuracy: 0.6907\n",
      "DR: 0.4 DPR: 0.1 Accuracy: 0.6907\n",
      "DR: 0.4 DPR: 0.2 Accuracy: 0.6907\n"
     ]
    }
   ],
   "source": [
    "drop_rates = [0.0, 0.2, 0.3, 0.4]\n",
    "drop_path_rates = [0.0, 0.1, 0.2]\n",
    "results = {}\n",
    "\n",
    "for dr in drop_rates:\n",
    "    for dpr in drop_path_rates:\n",
    "        acc = rates(dr, dpr)\n",
    "        results[(dr, dpr)] = acc\n",
    "        print(f\"DR: {dr} DPR: {dpr} Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc3961",
   "metadata": {},
   "source": [
    "# Learning Rate and Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d2d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(learning_rate, weight_decay, seed = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=0,\n",
    "                            drop_path_rate=0,\n",
    "                            num_classes=2)\n",
    "    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Dropout\":\n",
    "            m.p = 0.0\n",
    "        if m.__class__.__name__ == \"DropPath\":\n",
    "            m.drop_prob = 0.0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "    return acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "548f2dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1e-05 WD: 0 Accuracy: 0.5258\n",
      "LR: 1e-05 WD: 1e-05 Accuracy: 0.5258\n",
      "LR: 1e-05 WD: 0.0001 Accuracy: 0.5258\n",
      "LR: 1e-05 WD: 0.0003 Accuracy: 0.5258\n",
      "LR: 3e-05 WD: 0 Accuracy: 0.6082\n",
      "LR: 3e-05 WD: 1e-05 Accuracy: 0.6082\n",
      "LR: 3e-05 WD: 0.0001 Accuracy: 0.6082\n",
      "LR: 3e-05 WD: 0.0003 Accuracy: 0.6082\n",
      "LR: 0.0001 WD: 0 Accuracy: 0.7216\n",
      "LR: 0.0001 WD: 1e-05 Accuracy: 0.7216\n",
      "LR: 0.0001 WD: 0.0001 Accuracy: 0.7216\n",
      "LR: 0.0001 WD: 0.0003 Accuracy: 0.7216\n",
      "LR: 0.0003 WD: 0 Accuracy: 0.7113\n",
      "LR: 0.0003 WD: 1e-05 Accuracy: 0.7113\n",
      "LR: 0.0003 WD: 0.0001 Accuracy: 0.7113\n",
      "LR: 0.0003 WD: 0.0003 Accuracy: 0.7113\n"
     ]
    }
   ],
   "source": [
    "lrs = [1e-5, 3e-5, 1e-4, 3e-4]\n",
    "weight_decays = [0, 1e-5, 1e-4, 3e-4]\n",
    "results = {}\n",
    "\n",
    "for learning_rate in lrs:\n",
    "    for wd in weight_decays:\n",
    "        acc = lr(learning_rate, wd)\n",
    "        results[(learning_rate, wd)] = acc\n",
    "        print(f\"LR: {learning_rate} WD: {wd} Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3b855",
   "metadata": {},
   "source": [
    "# Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "625afd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(batch_size, seed = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=0,\n",
    "                            drop_path_rate=0,\n",
    "                            num_classes=2)\n",
    "    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Dropout\":\n",
    "            m.p = 0.0\n",
    "        if m.__class__.__name__ == \"DropPath\":\n",
    "            m.drop_prob = 0.0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "    return acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7638158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 16 Accuracy: 0.7320\n",
      "Batch Size: 32 Accuracy: 0.7216\n",
      "Batch Size: 64 Accuracy: 0.6701\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [16, 32, 64]\n",
    "results = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    acc = batch(batch_size)\n",
    "    results[batch_size] = acc\n",
    "    print(f\"Batch Size: {batch_size} Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e75b30",
   "metadata": {},
   "source": [
    "# Learning Rate Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7eaedc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7319587628865979\n"
     ]
    }
   ],
   "source": [
    "# Cosine Annealing\n",
    "def cosine_annealing(seed=42):\n",
    "    \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=0,\n",
    "                            drop_path_rate=0,\n",
    "                            num_classes=2)\n",
    "    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Dropout\":\n",
    "            m.p = 0.0\n",
    "        if m.__class__.__name__ == \"DropPath\":\n",
    "            m.drop_prob = 0.0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    return acc\n",
    "\n",
    "result = cosine_annealing()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32c25ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7319587628865979\n"
     ]
    }
   ],
   "source": [
    "# Cosine Annealing Warm Restarts\n",
    "def cosine_annealing_wr(seed=42):\n",
    "    \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=0,\n",
    "                            drop_path_rate=0,\n",
    "                            num_classes=2)\n",
    "    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Dropout\":\n",
    "            m.p = 0.0\n",
    "        if m.__class__.__name__ == \"DropPath\":\n",
    "            m.drop_prob = 0.0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=1,\n",
    "        T_mult=1)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    return acc\n",
    "\n",
    "result = cosine_annealing_wr()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f2ca7",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6169c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")), # ensures each images has RGB components\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2, contrast=0.2, saturation=0.2\n",
    "    ),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder(\"data\", transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a5ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7319587628865979\n"
     ]
    }
   ],
   "source": [
    "def best_model(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator = generator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=0, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True, generator = torch.Generator().manual_seed(seed), num_workers=0, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = timm.create_model(\"efficientnet_b0\", \n",
    "                            pretrained=True,\n",
    "                            drop_rate=0,\n",
    "                            drop_path_rate=0,\n",
    "                            num_classes=2)\n",
    "    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Dropout\":\n",
    "            m.p = 0.0\n",
    "        if m.__class__.__name__ == \"DropPath\":\n",
    "            m.drop_prob = 0.0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "    return acc\n",
    "\n",
    "result = best_model()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4321f",
   "metadata": {},
   "source": [
    "# Final Paramters\n",
    "- Drop Rate: 0\n",
    "- Drop Path Rate: 0\n",
    "- Learning Rate: 1e-4\n",
    "- Batch Size: 16\n",
    "- Learning Rate Scheduler: Doesn't need one\n",
    "- Data Augmentation: Doesn't need one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
